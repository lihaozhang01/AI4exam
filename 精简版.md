-----

### **AI智能试卷助手 (MVP版) - 开发计划与流程**

#### 1\. MVP核心目标 (MVP Goal)

开发一个无需登录的、单页面的Web应用。用户可以粘贴文本、配置要求，立即生成一份一次性的AI试卷。完成作答后，系统能即时给出所有题目的反馈（包括对论述题的AI批改），**关闭或刷新页面后，所有内容消失**。

#### 2\. MVP核心功能模块 (MVP Core Features)

1.  **API Key配置**:
      * 首次访问时，要求用户输入自己的AI API Key。
      * Key将仅保存在浏览器的`localStorage`中，供本次及后续访问使用，不会上传至服务器。
2.  **内容输入模块**:
      * **（简化）** 只支持用户直接**粘贴大段文本**作为知识源。暂不支持文件上传。
3.  **试卷生成配置模块**:
      * 允许用户选择生成的题目类型（选择题、填空题、论述题）。
      * 允许用户配置题目数量和难度。
4.  **一次性试卷交互模块**:
      * **（核心简化）** AI生成的试卷被动态渲染在页面上，不存入任何数据库。
      * 用户在页面上直接作答。
      * 提交后，客观题立即批改，论述题调用AI进行批改并展示反馈。
      * 提供“与AI讨论”的对话功能，以深入理解题目。

#### 3\. 简化的技术选型 (Simplified Tech Stack)

  * **前端 (Frontend)**

      * 核心框架: `React` + `Vite`
      * UI组件库: `Ant Design` (提供表单、卡片、模态框等，极大加速开发)
      * API请求: `Axios`
      * 状态管理: `Zustand` (极其轻量，非常适合管理一次性会话的状态)

  * **后端 (Backend)**

      * 核心框架: `FastAPI` (Python)
      * AI SDK: `google-generativeai`
      * 数据校验: `Pydantic`
      * **（移除）** 数据库相关的`SQLAlchemy`, `Alembic`以及用户认证相关的`passlib`, `python-jose`在本阶段完全不需要。



-----

### **MVP分步开发流程 (2人团队版)**

这是一个为期约 **1-2周** 的冲刺计划，专为2人团队（一名前端，一名后端）设计。

#### **第零步：启动与契约 (Day 1)**

  * **任务**:
    1.  **项目初始化**: 前后端分别创建好自己的代码仓库 (`git init`) 和基础项目结构（Vite项目/FastAPI项目）。
    2.  **API契约会议 (1小时)**: 双方坐在一起，**最终敲定**上述的两个API接口的URL、请求和响应结构。这是整个开发周期的基石。
    3.  **文档化**: 后端负责人将敲定的API结构写在一个共享的Markdown文件（如`API_CONTRACT.md`）中，提交到任一仓库。
  * **产出**:
      * 两个空的、但可以运行的React和FastAPI项目。
      * 一份作为“法律”的API接口文档。

#### **第一步：后端核心逻辑开发 (Day 2-4)**

  * **负责人**: 后端开发者。
  * **任务**:
    1.  **实现`/api/generate-test`接口**:
          * 不连接真实AI，先编写一个\*\*“假”的实现\*\*：无论收到什么请求，都返回一个固定格式的、写死的JSON试卷数据。这可以让前端开发者立即开始工作。
          * 编写与Google Gemini API通信的模块。
          * **关键任务**: **设计和调试Prompt**。这是整个应用效果的核心。需要反复尝试，如何让AI根据输入文本和要求，稳定地生成结构化的试卷JSON。
    2.  **实现`/api/evaluate-essay`接口**:
          * 同样，先做一个返回固定批改结果的“假”接口。
          * 设计和调试用于批改论述题的Prompt。
  * **产出**:
      * 两个功能完整的后端API接口，能够接收请求并返回真实的AI生成结果。

#### **第二步：前端UI与模拟数据开发 (Day 2-5)**

  * **负责人**: 前端开发者。
  * **任务**:
    1.  **搭建UI框架**:
          * 根据“详细交互逻辑方案”，使用Ant Design组件搭建出主界面：左侧是“知识源”和“出题要求”区域，右侧是等待生成的试卷区域。
          * 实现API Key输入的模态框。
    2.  **模拟数据驱动开发**:
          * 在代码中创建一个`mock-data.js`文件，内容就是`API_CONTRACT.md`里定义的响应体JSON。
          * 开发试卷渲染逻辑：读取这个模拟数据，将题目卡片列表成功渲染到页面上。
    3.  **开发交互功能**:
          * 实现用户的作答交互（点击选项、输入文本）。
          * 实现“完成批改”按钮的逻辑：点击后，根据模拟数据中的答案，立即在界面上显示对错（✔/✖），并显示解析。
          * 实现论述题卡片内“AI批阅中...”的加载状态。
  * **产出**:
      * 一个功能完整的、无需后端也能独立运行的UI界面。用户已经可以在上面“假装”完成一次完整的出题和答题流程。

#### **第三步：前后端联调与部署 (Day 6-8)**

  * **负责人**: 前后端协同工作。
  * **任务**:
    1.  **连接API**: 前端开发者将API请求从指向本地模拟数据，切换为指向后端开发者提供的真实API地址。
    2.  **联调与修复**: 这是问题集中爆发的时期。可能会遇到：
          * 跨域问题（CORS）。
          * 数据格式与约定不符。
          * AI返回结果不稳定导致前端解析错误。
          * 请求超时。
          * **坐在一起，共同解决问题。**
    3.  **实现AI讨论功能**: 在联调基本成功后，快速实现“与AI讨论”的聊天窗口，并对接一个新的、简单的`/api/discuss`接口。
    4.  **部署**:
          * 后端开发者编写`Dockerfile`，将FastAPI应用部署到[Render](https://render.com/)或[Railway](https://railway.app/)的免费套餐上。
          * 前端开发者将React应用一键部署到[Vercel](https://vercel.com/)或[Netlify](https://www.netlify.com/)。
  * **产出**:
      * 一个部署在公网、可供任何人访问和测试的MVP版本。

#### **第四步：测试、收集反馈与迭代 (Day 9-10)**

  * **任务**:
    1.  **内部测试**: 团队成员自己作为用户，完整地使用产品，寻找Bug和体验不佳之处。
    2.  **小范围分享**: 将链接发给几个朋友或潜在用户，请他们试用并提供最直接的反馈。
    3.  **记录问题**: 将发现的所有问题和收到的所有建议，记录到GitHub的Issues中，作为下一个迭代周期的“待办事项”。
  * **产出**:
      * MVP v1.0版本。
      * 一份宝贵的初始用户反馈和一份清晰的下一步工作清单。